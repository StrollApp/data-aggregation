{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-reporter",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-google",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "street_data = pd.read_csv('berkeleyWays.csv')\n",
    "node_data = pd.read_csv('berkeleyNodes.csv') # TODO: multiply by 10^7 and store as int\n",
    "edge_data = None\n",
    "node_set = set() # set of all non-redundant nodes\n",
    "node_id_to_index = {} # maps node id to index of csv file\n",
    "node_adj = {} # all edges incident to a node\n",
    "node_degrees = {} # degrees of all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-plumbing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# determines the degrees of nodes to see what we can delete\n",
    "node_data['id'] = node_data['id'].apply(int)\n",
    "node_data['latitude'] = node_data['latitude'].apply(float)\n",
    "node_data['longitude'] = node_data['longitude'].apply(float)\n",
    "\n",
    "for cell in node_data['id']:\n",
    "    node_degrees[cell] = 0\n",
    "    \n",
    "for index, row in street_data.iterrows():\n",
    "    string_of_nodes = row['node_ids']\n",
    "    list_of_nodes = string_of_nodes.split('-')\n",
    "    for i in range(len(list_of_nodes)):\n",
    "        if len(list_of_nodes) == 0:\n",
    "            break\n",
    "        node = int(list_of_nodes[i])\n",
    "        if i == 0 or i == len(list_of_nodes) - 1:\n",
    "            if node in node_degrees:\n",
    "                node_degrees[node] += 1\n",
    "        else:\n",
    "            if node in node_degrees:\n",
    "                node_degrees[node] += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-niagara",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scans through all nodes and keeps only relevant ones, adds every relevant segment to edge_data\n",
    "node_hashmap = node_data.set_index('id').T.to_dict('list')\n",
    "\n",
    "THRESHOLD = math.pi / 6\n",
    "CENTER = math.pi\n",
    "\n",
    "def get_angle(curr_coords, prev_coords, next_coords):\n",
    "    b = np.array(curr_coords)\n",
    "    a = np.array(prev_coords)\n",
    "    c = np.array(next_coords)\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    prev_angle = math.atan2(ba[1], ba[0])\n",
    "    next_angle = math.atan2(bc[1], bc[0])\n",
    "    return (next_angle - prev_angle) % (2 * math.pi)\n",
    "\n",
    "edge_list = {}\n",
    "edge_list['name'] = []\n",
    "edge_list['start_id'] = []\n",
    "edge_list['end_id'] = []\n",
    "edge_list['highway'] = []\n",
    "\n",
    "for index, row in street_data.iterrows():\n",
    "    string_of_nodes = row['node_ids']\n",
    "    list_of_nodes = string_of_nodes.split('-')\n",
    "    nodes_to_keep = []\n",
    "    last = 0\n",
    "    nodes_to_keep.append(int(list_of_nodes[0]))\n",
    "    for i in range(1, len(list_of_nodes) - 1):\n",
    "        curr_node = int(list_of_nodes[i])\n",
    "        prev_node = int(list_of_nodes[last])\n",
    "        next_node = int(list_of_nodes[i + 1])\n",
    "        if node_degrees[curr_node] > 2: # this is an intersection\n",
    "            nodes_to_keep.append(curr_node)\n",
    "            last = i\n",
    "            continue\n",
    "        curr_coords = node_hashmap[curr_node]\n",
    "        prev_coords = node_hashmap[prev_node]\n",
    "        next_coords = node_hashmap[next_node]\n",
    "        angle = get_angle(curr_coords, prev_coords, next_coords)\n",
    "        if abs(angle - CENTER) < THRESHOLD: # turn in the road\n",
    "            continue\n",
    "        nodes_to_keep.append(curr_node)\n",
    "        last = i\n",
    "    if len(nodes_to_keep) > 0 and nodes_to_keep[0] != int(list_of_nodes[len(list_of_nodes) - 1]):\n",
    "        nodes_to_keep.append(int(list_of_nodes[len(list_of_nodes) - 1]))\n",
    "    for i in range(len(nodes_to_keep) - 1):\n",
    "        edge_list['name'].append(row['name'])\n",
    "        edge_list['highway'].append(row['highway'])\n",
    "        edge_list['start_id'].append(nodes_to_keep[i])\n",
    "        edge_list['end_id'].append(nodes_to_keep[i + 1])\n",
    "    for node in nodes_to_keep:\n",
    "        node_set.add(node)\n",
    "        \n",
    "edge_data = pd.DataFrame(edge_list)\n",
    "node_data = node_data[node_data['id'].isin(node_set)]\n",
    "for index, row in node_data.iterrows():\n",
    "    node_id_to_index[int(row['id'])] = index\n",
    "\n",
    "display(node_data)\n",
    "display(edge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-colorado",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adds columns for all other features a street segment could have\n",
    "nan = [None for b in range(len(edge_data))]\n",
    "\n",
    "features = [\n",
    "    'crime_count', \n",
    "    'tree_count', \n",
    "    'light_count', \n",
    "    'business_count', \n",
    "    'signal_count', \n",
    "    'pavement_width', \n",
    "    'street_type', \n",
    "    'crime_ratio', \n",
    "    'tree_ratio', \n",
    "    'light_ratio', \n",
    "    'business_ratio', \n",
    "    'signal_ratio', \n",
    "    'region']\n",
    "\n",
    "for feature in features:\n",
    "    edge_data[feature] = nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-dress",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creates adjacency list for nodes\n",
    "for node in node_set:\n",
    "    node_adj[node] = {}\n",
    "    adjacent_edges = edge_data.loc[(edge_data['start_id'] == node) | (edge_data['end_id'] == node)].index.tolist()\n",
    "    node_adj[node] = set(adjacent_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes map data to csv files\n",
    "edge_data.to_csv('Map_Edges.csv')\n",
    "node_data.to_csv('Map_Nodes.csv')\n",
    "counter = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-birmingham",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# utility functions to get distances\n",
    "\n",
    "def get_distance_btwn_points(x1, y1, x2, y2):\n",
    "    return sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "# finds distance between c = (x3, y3) to line defined by a = (x1, y1) and b = (x2, y2)\n",
    "def get_distance_btwn_point_and_line(x1, y1, x2, y2, x3, y3):\n",
    "    p1 = np.array([x1, y1])\n",
    "    p2 = np.array([x2, y2])\n",
    "    p3 = np.array([x3, y3])\n",
    "    ab = p2 - p1\n",
    "    ba = p1 - p2\n",
    "    ac = p3 - p1\n",
    "    bc = p3 - p2\n",
    "    bac = np.dot(ab, ac)\n",
    "    cba = np.dot(ba, bc)\n",
    "    if bac < 0 and cba < 0:\n",
    "        return None\n",
    "    elif bac < 0:\n",
    "        return ac[0] * ac[0] + ac[1] * ac[1]\n",
    "    elif cba < 0:\n",
    "        return bc[0] * bc[0] + bc[1] * bc[1]\n",
    "    cross_product = np.cross(ab, ac)\n",
    "    return cross_product * cross_product / (ab[0] * ab[0] + ab[1] * ab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-collector",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gets street segment indices for a latitude and longitude\n",
    "\n",
    "index_list = edge_data.index.tolist()\n",
    "start_ids = edge_data['start_id'].tolist()\n",
    "end_ids = edge_data['end_id'].tolist()\n",
    "start_indices = [node_id_to_index[b] for b in start_ids]\n",
    "end_indices = [node_id_to_index[b] for b in end_ids]\n",
    "start_latitudes = [node_data.at[start_index, 'latitude'] for start_index in start_indices]\n",
    "start_longitudes = [node_data.at[start_index, 'longitude'] for start_index in start_indices]\n",
    "end_latitudes = [node_data.at[end_index, 'latitude'] for end_index in end_indices]\n",
    "end_longitudes = [node_data.at[end_index, 'longitude'] for end_index in end_indices]\n",
    "\n",
    "# gets the street segment closest to the latitude and longitude of a given point\n",
    "# current implementation will assume streets are straight lines and the earth is flat\n",
    "# also current implementation goes through all edges which is slow, implement regions in the future\n",
    "# REQUIRES intersections to have coordinates\n",
    "def get_block(latitude, longitude):\n",
    "    min_distance = float('inf')\n",
    "    min_street_index = -1\n",
    "    for index, start_latitude, start_longitude, end_latitude, end_longitude in zip(index_list, start_latitudes, start_longitudes, end_latitudes, end_longitudes):\n",
    "        current_distance = get_distance_btwn_point_and_line(\n",
    "            start_latitude, start_longitude, end_latitude, end_longitude, latitude, longitude)\n",
    "        if current_distance < min_distance:\n",
    "            min_distance = current_distance\n",
    "            min_street_index = index\n",
    "    return min_street_index\n",
    "\n",
    "# gets the k closest segments to the given point\n",
    "# REQUIRES intersections to have coordinates\n",
    "def get_closest_blocks(latitude, longitude, k):\n",
    "    print(counter[0])\n",
    "    counter[0] += 1\n",
    "    pq = [(get_distance_btwn_point_and_line(\n",
    "        start_latitude, start_longitude, end_latitude, end_longitude, latitude, longitude), index) \n",
    "          for index, start_latitude, start_longitude, end_latitude, end_longitude \n",
    "          in zip(index_list, start_latitudes, start_longitudes, end_latitudes, end_longitudes)]\n",
    "    pq.sort()\n",
    "    closest = [pq[i][1] for i in range(k)]\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-writer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# increments the value of parameter at the k street segments closest to location\n",
    "def set_zero(parameter):\n",
    "    edge_data[parameter] = [0 for b in range(len(edge_data))]\n",
    "\n",
    "def update_street_data(latitude, longitude, parameter, k = 1):\n",
    "    if k == 1:\n",
    "        index = get_block(latitude, longitude)\n",
    "        if edge_data.at[index, parameter] is None:\n",
    "            edge_data.at[index, parameter] = 0\n",
    "        edge_data.at[index, parameter] += 1\n",
    "    else:\n",
    "        index = get_closest_blocks(latitude, longitude, k)\n",
    "        if index:\n",
    "            for block in index:\n",
    "                if edge_data.at[block, parameter] is None:\n",
    "                    edge_data.at[block, parameter] = 0\n",
    "                edge_data.at[block, parameter] += 1\n",
    "                \n",
    "def update_street_data_coords(coords, parameter, k = 1):\n",
    "    if k == 1:\n",
    "        index = get_block(coords[0], coords[1])\n",
    "        edge_data.at[index, parameter] += 1\n",
    "    else:\n",
    "        index = get_closest_blocks(coords[0], coords[1], k)\n",
    "        for block in index:\n",
    "            edge_data.at[block, parameter] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-november",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adds crime data\n",
    "import re\n",
    "\n",
    "crime = pd.read_csv('crimes.csv')\n",
    "crime = crime[['Block_Location']]\n",
    "pattern = '\\((.*)\\)'\n",
    "\n",
    "def extract_coords(given_string, split, lat_first = True):\n",
    "    s = re.search(pattern, given_string).group(1)\n",
    "    coords = s.split(split)\n",
    "    if lat_first:\n",
    "        return float(coords[0]), float(coords[1])\n",
    "    return float(coords[1]), float(coords[0])\n",
    "\n",
    "crime['Block_Location'] = crime['Block_Location'].apply(extract_coords, args = (', ', True))\n",
    "\n",
    "set_zero('crime_count')\n",
    "\n",
    "crime['Block_Location'].apply(update_street_data_coords, args=('crime_count', 3))\n",
    "\n",
    "display(edge_data)\n",
    "\n",
    "edge_data.to_csv('Edge_Data_Crime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-permit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adds tree data\n",
    "trees = pd.read_csv('City_Trees.csv')\n",
    "trees = trees[['Latitude', 'Longitude']]\n",
    "\n",
    "trees['coordinates'] = list(zip(trees.Latitude, trees.Longitude))\n",
    "\n",
    "set_zero('tree_count')\n",
    "\n",
    "trees['coordinates'].apply(update_street_data_coords, args=('tree_count', 1))\n",
    "\n",
    "display(edge_data)\n",
    "\n",
    "edge_data.to_csv('Edge_Data_Tree.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-hampshire",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adds light data\n",
    "streetLights = pd.read_csv('streetLights.csv')\n",
    "streetLights = streetLights[['the_geom']]\n",
    "\n",
    "streetLights['the_geom'] = streetLights['the_geom'].apply(extract_coords, args = (' ', False))\n",
    "\n",
    "set_zero('light_count')\n",
    "\n",
    "streetLights['the_geom'].apply(update_street_data_coords, args=('light_count', 1))\n",
    "\n",
    "display(edge_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-tennessee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adds business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-advantage",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adds park data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-newton",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# converts DataFrame into csv files\n",
    "\n",
    "# creates dash separated list of edge indices adjacent to a node\n",
    "def create_string_from_set(node):\n",
    "    adj = [str(b) for b in node_adj[node]]\n",
    "    return '-'.join(adj)\n",
    "\n",
    "node_data['adjacencies'] = [None for b in range(len(node_data))]\n",
    "node_data['adjacencies'] = node_data['id'].apply(create_string_from_set)\n",
    "\n",
    "# writes to files\n",
    "node_data.to_csv('Node_Data.csv')\n",
    "edge_data.to_csv('Edge_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
